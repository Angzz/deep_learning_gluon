{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd, image, gluon, init\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "%matplotlib inline\n",
    "\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_augs = [image.HorizontalFlipAug(.5),image.RandomCropAug((224,224))]\n",
    "test_augs = [image.CenterCropAug((224,224))]\n",
    "\n",
    "def transform(data, label, augs):\n",
    "    data = data.astype('float32')\n",
    "    for aug in augs:\n",
    "        data = aug(data)\n",
    "    data = nd.transpose(data, (2,0,1))\n",
    "    return data, nd.array([label]).asscalar().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "fname = gluon.utils.download('https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/hotdog.zip',path=data_dir, sha1_hash='fba480ffa8aa7e0febbb511d181409f899b9baa5')\n",
    "\n",
    "with zipfile.ZipFile(fname, 'r') as f:\n",
    "    f.extractall(data_dir)\n",
    "    \n",
    "train_imgs = gluon.data.vision.ImageFolderDataset(data_dir+'/hotdog/train',transform=lambda X, y: transform(X, y, train_augs))\n",
    "test_imgs = gluon.data.vision.ImageFolderDataset(data_dir+'/hotdog/test',transform=lambda X, y: transform(X, y, test_augs))\n",
    "\n",
    "data = gluon.data.DataLoader(train_imgs, 32, shuffle=True)\n",
    "\n",
    "batch_size=64\n",
    "train_data = gluon.data.DataLoader(train_imgs, batch_size, shuffle=True)\n",
    "test_data = gluon.data.DataLoader(test_imgs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained_net = models.resnet18_v2(pretrained=True)\n",
    "\n",
    "finetune_net = models.resnet18_v2(classes=2)\n",
    "finetune_net.features = pretrained_net.features\n",
    "finetune_net.output.initialize(init.Xavier())\n",
    "\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "net.hybridize()\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': learning_rate, 'wd': wd})\n",
    "\n",
    "\n",
    "epochs=10\n",
    "learning_rate=0.01\n",
    "wd=0.001\n",
    "\n",
    "utils.train(train_data, test_data, finetune_net, loss, trainer, ctx, epochs)\n",
    "train_data, test_data, finetune_net, loss, trainer, ctx, epochs, print_batches=None\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc, n, m = 0.0, 0.0, 0.0, 0.0\n",
    "        start = time()\n",
    "        for i, batch in enumerate(train_data):\n",
    "            data, label, batch_size = _get_batch(batch, ctx)\n",
    "            losses = []\n",
    "            with autograd.record():\n",
    "                outputs = [net(X) for X in data]\n",
    "                losses = [loss(yhat, y) for yhat, y in zip(outputs, label)]\n",
    "            for l in losses:\n",
    "                l.backward()\n",
    "            train_acc += sum([(yhat.argmax(axis=1)==y).sum().asscalar()for yhat, y in zip(outputs, label)])\n",
    "            train_loss += sum([l.sum().asscalar() for l in losses])\n",
    "            trainer.step(batch_size)\n",
    "            n += batch_size\n",
    "            m += sum([y.size for y in label])\n",
    "            if print_batches and (i+1) % print_batches == 0:\n",
    "                print(\"Batch %d. Loss: %f, Train acc %f\" % (n, train_loss/n, train_acc/m))\n",
    "        test_acc = evaluate_accuracy(test_data, net, ctx)\n",
    "        print(\"Epoch %d. Loss: %.3f, Train acc %.2f, Test acc %.2f, Time %.1f sec\" % (epoch, train_loss/n, train_acc/m, test_acc, time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_hotdog(net, fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        img = image.imdecode(f.read())\n",
    "    data, _ = transform(img, -1, test_augs)\n",
    "    plt.imshow(data.transpose((1,2,0)).asnumpy()/255)\n",
    "    data = data.expand_dims(axis=0)\n",
    "    out = net(data.as_in_context(ctx[0]))\n",
    "    out = nd.SoftmaxActivation(out)\n",
    "    pred = int(nd.argmax(out, axis=1).asscalar())\n",
    "    prob = out[0][pred].asscalar()\n",
    "    label = train_imgs.synsets\n",
    "    return 'With prob=%f, %s'%(prob, label[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classify_hotdog(finetune_net, '../img/real_hotdog.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
